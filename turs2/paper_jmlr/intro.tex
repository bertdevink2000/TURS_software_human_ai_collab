\section{Introduction} \label{sec:intro}
When using predictive models in sensitive real-world scenarios, such as in health care, analysts seek for intelligible and reliable explanations for predictions. Classification rules have considerable advantages here, as they are directly readable by humans. While rules all seem alike, however, some are more interpretable than others. The reason lies in the subtle differences of how rules form a model. Specifically, rules can form an unordered \emph{rule set}, or an explicitly ordered \emph{rule list}; further, they can be categorized as probabilistic or non-probabilistic. 

%In practice, probabilistic and unordered rule sets should be preferred, for the following reasons. First, when a human is responsible to make the final decision, predictions \emph{with} probability estimates provide more information w.r.t.\ the expected ``utility". Next, rule lists are more difficult to interpret than rule sets, as the interpretation of any rule depends on all preceding rules. 
In practice, probabilistic rules should be preferred because they provide information about the uncertainty of the predicted outcomes, and thus are useful when a human is responsible to make the final decision, as the expected ``utility" can be calculated. 
%1) when a human is responsible to make the final decision, predictions \emph{with} probability estimates provide more information w.r.t.\ the expected ``utility", and 2) it provides more information about how a certain predicted outcome is produced, which increases the algorithm transparency.
 Meanwhile, unordered rule sets should also be preferred, as they have better properties regarding interpretability than ordered rule lists. 
 While no agreement has been reached on the precise definition of interpretability of machine learning models 
 \citep{murdoch2019interpretable,molnar2020interpretable}, we specifically treat interpretability with domain experts in mind. From this perspective, a model's interpretability intuitively depends on two aspects: the degree of difficulty for a human to comprehend the model itself, and to understand a single prediction. Unordered probabilistic rule sets are favorable with respect to both aspects, for the following reasons. First, comprehending ordered rule lists requires comprehending not only each individual rule, but also the relationship among the rules, while comprehending unordered rule sets requires only the former. Second, the explanation for a single prediction of an ordered rule list must contain the rule that the instance satisfies, together with all of its preceding rules, which becomes incomprehensible when the number of preceding rules is large. 

Further, crucially, existing methods for rule set learning claim to learn unordered rule sets, but most of them are not truly unordered. The problem is caused by \emph{overlap}, i.e., a single instance satisfying multiple rules. Ad-hoc schemes are widely used to resolve prediction conflicts caused by overlaps, typically by ranking the involved rules with certain criteria and always selecting the highest ranked rule \citep{zhang2020diverseRuleSets,lakkaraju2016interpretable} (e.g., the most accurate one). This, however, imposes implicit orders among rules, making them entangled instead of truly unordered. 

This can badly harm interpretability: to explain a single prediction for an instance, it is now insufficient to only provide the rules the instance satisfies, because other higher-ranked rules that the instance does \emph{not} satisfy are also part of the explanation. For instance, imagine a patient is predicted to have \emph{Flu} because they have \emph{Fever}. If the model also contains the higher-ranked rule \emph{``Blood in stool $\rightarrow$ Dysentery"}, the explanation should include the fact that \emph{``Blood in stool"} is not true, because otherwise the prediction would change to \emph{Dysentery}. If the model contains many rules, it becomes impractical to have to go over all higher-ranked rules for each prediction. 

Learning truly unordered probabilistic rule sets is a very challenging problem though. Classical rule set learning methods usually adopt a separate-and-conquer strategy, often sequential covering: they iteratively find the next rule and remove instances satisfying this rule. This includes 1) binary classifiers that learn rules only for the ``positive" class \citep{furnkranz2012foundations}, and 2) its extension to multi-class targets by the one-versus-rest paradigm, i.e., learning rules for each class one by one \citep{cohen1995ripper,clark1991cn2Improve}. Importantly, by iteratively removing instances the \emph{probabilistic predictive conflicts} caused by overlaps, i.e., rules having different probability estimates for the target, are ignored. Recently proposed rule learning methods go beyond separate-and-conquer by leveraging discrete optimization techniques \citep{zhang2020diverseRuleSets,wang2017bayesian,yang2021learning,lakkaraju2016interpretable,dash2018boolean}, but this comes at the cost of requiring a binary feature matrix as input. Moreover, these methods are neither probabilistic nor truly unordered, as they still use ad-hoc schemes to resolve predictive conflicts caused by overlaps. 

\emph{Approach and contributions.}
To tackle these challenges and learn truly unordered probabilistic rules, we propose a novel approach that we only allow overlaps that are formed by rules with ``similar" probabilistic output. In this case, when an individual instance is covered by multiple rules, the conflict caused by different rules is minimized. 

In practice, to characterize the similarity among rules' probabilistic outputs, we need to trade off between three quantities: the differences between the probability estimates, the size of the overlap, and the model complexity. Instead of explicitly defining hyper-parameters to control the trade off, we take a principled model selection approach, for which we formally define rule sets as probabilistic models. Specifically, we propose an effective and novel approach to formalize the conditional class probability estimates: informally, we take the union for the intersection. 

We further design a model selection criterion based on the minimum description length (MDL) principle \citep{grunwald2019minimum}, which does not require a regularization parameter to be tuned. 
We resort to heuristics for optimization as the search space combined with the model selection criterion do not allow efficient search. Yet, we carefully and extensively extend the common heuristic approach for learning decision rules from data, in the following aspects. First, we consider a ``learning rate" heuristic, i.e., the decrease of our optimization score (to be minimized) \emph{per extra covered instance} as the quality measure for \emph{potentially incomplete rule sets}. Second, we take a novel beam search approach, such that 1) the degree of ``patience" is considered by using a diverse beam search approach, and 2) an auxiliary beam together with a surrogate score is proposed, in order to resolve the issue that, as a unique challenge coming along with our model formalization that allows overlap, rules that have been added to the rule set may become obstacles for new rules. 
Third, a local constraint is used for ``looking-ahead" on the potential for the instances being left out when rules are being refined (i.e., when more literals are added to the rules). 

Finally, we benchmark our algorithm, named TURS, for Truly Unordered Rule Sets with extensive empirical comparisons against a wide range of rule-based methods. We show that TURS has superior performance in the following aspects: 1) TURS has very competitive predictive performance measured by ROC-AUC; 2) TURS can empirically learn truly unordered rules: the probabilistic conflicts caused by overlaps are minimized, in the sense that the influence is little even if we predict for instances covered by multiple rules by randomly picking a rule from these rules; 3) TURS learns a set of decision rules with probability estimates for the target variable that can generalize well to unseen data; and 4) TURS produces simpler models in comparison to competitor algorithms. 

%We adopt a probabilistic model selection approach for rule set learning, for which we design a criterion based on the minimum description length (MDL) principle \citep{grunwald2019minimum}. 

%Second, we propose a novel surrogate score based on decision trees that we use to evaluate the potential of incomplete rule sets. Third, we are the first to design a rule learning algorithm that deals with probabilistic conflicts caused by overlaps already during the rule learning process. We point out that rules that have been added to the rule set may become obstacles for new rules, and hence carefully design a two-phase heuristic algorithm, for which we adopt diverse beam search \citep{matthijs2012diverse}. 

%Last, we benchmark our method, named \textsc{Turs}, for Truly Unordered Rule Sets, against a wide range of methods. We show that the rule sets learned by \textsc{Turs}, apart from being probabilistic and truly unordered, have better predictive performance than existing rule list and rule set methods. 

