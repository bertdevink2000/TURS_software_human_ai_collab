\section{Introduction} \label{sec:intro}
When using predictive models in sensitive real-world scenarios, such as in health care, analysts seek for intelligible and reliable explanations for predictions. Classification rules have considerable advantages here, as they are directly readable by humans. While rules all seem alike, however, some are more interpretable than others. The reason lies in the subtle differences of how rules form a model. Specifically, rules can form an unordered \emph{rule set}, or an explicitly ordered \emph{rule list}; further, they can be categorized as probabilistic or non-probabilistic. 

%In practice, probabilistic and unordered rule sets should be preferred, for the following reasons. First, when a human is responsible to make the final decision, predictions \emph{with} probability estimates provide more information w.r.t.\ the expected ``utility". Next, rule lists are more difficult to interpret than rule sets, as the interpretation of any rule depends on all preceding rules. 
In practice, probabilistic rules should be preferred because they provide information about the uncertainty of the predicted outcomes, and thus are useful when a human is responsible to make the final decision, as the expected ``utility" can be calculated. 
%1) when a human is responsible to make the final decision, predictions \emph{with} probability estimates provide more information w.r.t.\ the expected ``utility", and 2) it provides more information about how a certain predicted outcome is produced, which increases the algorithm transparency.
 Meanwhile, unordered rule sets should also be preferred, as they have better properties regarding interpretability than ordered rule lists. 
 While no agreement has been reached on the precise definition of interpretability of machine learning models 
 \citep{murdoch2019interpretable,molnar2020interpretable}, we specifically treat interpretability with domain experts in mind. From this perspective, a model's interpretability intuitively depends on two aspects: the degree of difficulty for a human to comprehend the model itself, and to understand a single prediction. Unordered probabilistic rule sets are favorable with respect to both aspects, for the following reasons. First, comprehending ordered rule lists requires comprehending not only each individual rule, but also the relationship among the rules, while comprehending unordered rule sets requires only the former. Second, the explanation for a single prediction of an ordered rule list must contain the rule that the instance satisfies, together with all of its preceding rules, which becomes incomprehensible when the number of preceding rules is large. 

Further, crucially, existing methods for rule set learning claim to learn unordered rule sets, but most of them are not truly unordered. The problem is caused by \emph{overlap}, i.e., a single instance satisfying multiple rules. Ad-hoc schemes are widely used to resolve prediction conflicts caused by overlaps, typically by ranking the involved rules with certain criteria and always selecting the highest ranked rule \citep{zhang2020diverseRuleSets,lakkaraju2016interpretable} (e.g., the most accurate one). This, however, imposes implicit orders among rules, making them entangled instead of truly unordered. 

%This can badly harm interpretability, due to the increased efforts required for domain experts to understand each individual prediction: it is insufficient to only provide the rules the instance satisfies, because other higher-ranked rules that the instance does \emph{not} satisfy are also part of the explanation. For instance, imagine a patient is predicted to have \emph{Flu} because they have \emph{Fever}. If the model also contains the higher-ranked rule \emph{``Blood in stool $\rightarrow$ Dysentery"}, the explanation should include the fact that \emph{``Blood in stool"} is not true, because otherwise the prediction would change to \emph{Dysentery}. If the model contains many rules, it becomes impractical to have to go over all higher-ranked rules for each prediction. 
This can badly harm interpretability: to explain a single prediction for an instance, it is now insufficient to only provide the rules the instance satisfies, because other higher-ranked rules that the instance does \emph{not} satisfy are also part of the explanation. For instance, imagine a patient is predicted to have \emph{Flu} because they have \emph{Fever}. If the model also contains the higher-ranked rule \emph{``Blood in stool $\rightarrow$ Dysentery"}, the explanation should include the fact that \emph{``Blood in stool"} is not true, because otherwise the prediction would change to \emph{Dysentery}. If the model contains many rules, it becomes impractical to have to go over all higher-ranked rules for each prediction. 

Learning truly unordered probabilistic rule sets is a very challenging problem though. Classical rule set learning methods usually adopt a separate-and-conquer strategy, often sequential covering: they iteratively find the next rule and remove instances satisfying this rule. This includes 1) binary classifiers that learn rules only for the ``positive" class \citep{furnkranz2012foundations}, and 2) its extension to multi-class targets by the one-versus-rest paradigm, i.e., learning rules for each class one by one \citep{cohen1995ripper,clark1991cn2Improve}. Importantly, by iteratively removing instances the \emph{probabilistic predictive conflicts} caused by overlaps, i.e., rules having different probability estimates for the target, are ignored. Recently proposed rule learning methods go beyond separate-and-conquer by leveraging discrete optimization techniques \citep{zhang2020diverseRuleSets,wang2017bayesian,yang2021learning,lakkaraju2016interpretable,dash2018boolean}, but this comes at the cost of requiring a binary feature matrix as input. Moreover, these methods are neither probabilistic nor truly unordered, as they still use ad-hoc schemes to resolve predictive conflicts caused by overlaps. 

\emph{Approach and contributions.}
To tackle these challenges and learn truly unordered probabilistic rules, we first formalize rule sets as probabilistic models. We adopt a probabilistic model selection approach for rule set learning, for which we design a criterion based on the minimum description length (MDL) principle \citep{grunwald2019minimum}. Second, we propose a novel surrogate score based on decision trees that we use to evaluate the potential of incomplete rule sets. Third, we are the first to design a rule learning algorithm that deals with probabilistic conflicts caused by overlaps already during the rule learning process. We point out that rules that have been added to the rule set may become obstacles for new rules, and hence carefully design a two-phase heuristic algorithm, for which we adopt diverse beam search \citep{matthijs2012diverse}. 
%Note that beam search is only possible given the essence of the global score for evaluating rule sets (instead of local heuristics only). 
Last, we benchmark our method, named \textsc{Turs}, for Truly Unordered Rule Sets, against a wide range of methods. We show that the rule sets learned by \textsc{Turs}, apart from being probabilistic and truly unordered, have better predictive performance than existing rule list and rule set methods. 

